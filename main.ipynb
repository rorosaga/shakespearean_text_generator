{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation ðŸ““âœï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before starting, define the **n-grams** to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works with 2, 3, and 4\n",
    "n_grams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caesar length:  25833\n",
      "Hamlet length:  37360\n",
      "Macbeth length:  23140\n"
     ]
    }
   ],
   "source": [
    "# loading shakespeare's works\n",
    "\n",
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "caesar = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "print(\"Caesar length: \", len(caesar))\n",
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "print(\"Hamlet length: \", len(hamlet))\n",
    "macbeth = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')\n",
    "print(\"Macbeth length: \", len(macbeth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lowering the case of the text and removing punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'tragedie', 'of', 'julius', 'caesar', 'by', 'william', 'shakespeare', '1599', 'actus']\n",
      "['the', 'tragedie', 'of', 'hamlet', 'by', 'william', 'shakespeare', '1599', 'actus', 'primus']\n",
      "['the', 'tragedie', 'of', 'macbeth', 'by', 'william', 'shakespeare', '1603', 'actus', 'primus']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# lowercase and remove punctuation\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = [word.lower() for word in text]\n",
    "    \n",
    "    # Remove punctuation from each word\n",
    "    text = [word.translate(str.maketrans('', '', string.punctuation)) for word in text]\n",
    "    \n",
    "    # Remove any empty strings that might result from words that were only punctuation\n",
    "    text = [word for word in text if word]\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Preprocess texts\n",
    "caesar_clean = preprocess_text(caesar)\n",
    "hamlet_clean = preprocess_text(hamlet)\n",
    "macbeth_clean = preprocess_text(macbeth)\n",
    "\n",
    "print(caesar_clean[:10])\n",
    "print(hamlet_clean[:10])\n",
    "print(macbeth_clean[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Creating the **list of n-grams** for each text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4-grams from Caesar:\n",
      "[('the', 'tragedie', 'of', 'julius'), ('tragedie', 'of', 'julius', 'caesar'), ('of', 'julius', 'caesar', 'by'), ('julius', 'caesar', 'by', 'william'), ('caesar', 'by', 'william', 'shakespeare')]\n",
      "\n",
      "4-grams from Hamlet:\n",
      "[('the', 'tragedie', 'of', 'hamlet'), ('tragedie', 'of', 'hamlet', 'by'), ('of', 'hamlet', 'by', 'william'), ('hamlet', 'by', 'william', 'shakespeare'), ('by', 'william', 'shakespeare', '1599')]\n",
      "\n",
      "4-grams from Macbeth:\n",
      "[('the', 'tragedie', 'of', 'macbeth'), ('tragedie', 'of', 'macbeth', 'by'), ('of', 'macbeth', 'by', 'william'), ('macbeth', 'by', 'william', 'shakespeare'), ('by', 'william', 'shakespeare', '1603')]\n"
     ]
    }
   ],
   "source": [
    "# list of n-grams for each text\n",
    "def get_ngrams(tokens, n):\n",
    "    return list(nltk.ngrams(tokens, n))\n",
    "\n",
    "# Get n-grams for each text\n",
    "caesar_ngrams = get_ngrams(caesar_clean, n_grams)\n",
    "hamlet_ngrams = get_ngrams(hamlet_clean, n_grams)\n",
    "macbeth_ngrams = get_ngrams(macbeth_clean, n_grams)\n",
    "\n",
    "print(f\"\\n{n_grams}-grams from Caesar:\")\n",
    "print(caesar_ngrams[:5])\n",
    "print(f\"\\n{n_grams}-grams from Hamlet:\")\n",
    "print(hamlet_ngrams[:5])\n",
    "print(f\"\\n{n_grams}-grams from Macbeth:\")\n",
    "print(macbeth_ngrams[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Counting the **frequency** of each ngram's subsequent token and the own ngram's frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram 'to be or not':\n",
      "Total count: 1\n",
      "Next tokens: {'to': 1}\n",
      "\n",
      "Raw data:\n",
      "{'count': 1, 'next_tokens': {'to': 1}}\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each n-gram's subsequent token\n",
    "# Example: from_ngram_to_next_token_counts[('to', 'be')] = {'count': 15, 'next_tokens': {'or': 10, 'not': 5}}\n",
    "# This means that the n-gram 'to be' is followed by 'or' 10 times and by 'not' 5 times, and the total count of ngram 'to be' is 15\n",
    "\n",
    "\n",
    "from_ngram_to_next_token_counts = {}\n",
    "\n",
    "def count_next_token(ngrams, tokens, dictionary, n):\n",
    "    for i in range(len(ngrams)):\n",
    "        if i < len(tokens) - n:  # Make sure we have a next token\n",
    "            ngram = ngrams[i]\n",
    "            next_token = tokens[i + n]  # Get the token that follows the ngram\n",
    "            \n",
    "            # If ngram doesn't exist, create new entry with count and next_tokens dictionary\n",
    "            if ngram not in dictionary:\n",
    "                dictionary[ngram] = {\n",
    "                    'count': 0,\n",
    "                    'next_tokens': {}\n",
    "                }\n",
    "            \n",
    "            # Increment total count for this ngram\n",
    "            dictionary[ngram]['count'] += 1\n",
    "            \n",
    "            # Add or increment next token count\n",
    "            if next_token not in dictionary[ngram]['next_tokens']:\n",
    "                dictionary[ngram]['next_tokens'][next_token] = 1\n",
    "            else:\n",
    "                dictionary[ngram]['next_tokens'][next_token] += 1\n",
    "\n",
    "# Count next tokens from each play\n",
    "count_next_token(caesar_ngrams, caesar_clean, from_ngram_to_next_token_counts, n_grams)\n",
    "count_next_token(hamlet_ngrams, hamlet_clean, from_ngram_to_next_token_counts, n_grams)\n",
    "count_next_token(macbeth_ngrams, macbeth_clean, from_ngram_to_next_token_counts, n_grams)\n",
    "\n",
    "# Testing function depending on number of ngrams\n",
    "if n_grams == 2:\n",
    "\n",
    "    ngram = ('to', 'be')\n",
    "    result = from_ngram_to_next_token_counts[ngram]\n",
    "    print(f\"N-gram '{ngram[0]} {ngram[1]}':\")\n",
    "    print(f\"Total count: {result['count']}\")\n",
    "    print(f\"Next tokens: {result['next_tokens']}\")\n",
    "\n",
    "    print(\"\\nRaw data:\")\n",
    "    print(from_ngram_to_next_token_counts[('to', 'be')])\n",
    "\n",
    "elif n_grams == 3:\n",
    "    ngram = ('to', 'be', 'or')\n",
    "    result = from_ngram_to_next_token_counts[ngram]\n",
    "    print(f\"N-gram '{ngram[0]} {ngram[1]} {ngram[2]}':\")\n",
    "    print(f\"Total count: {result['count']}\")\n",
    "    print(f\"Next tokens: {result['next_tokens']}\")\n",
    "\n",
    "    print(\"\\nRaw data:\")\n",
    "    print(from_ngram_to_next_token_counts[('to', 'be', 'or')])\n",
    "\n",
    "elif n_grams == 4:\n",
    "    ngram = ('to', 'be', 'or', 'not')\n",
    "    result = from_ngram_to_next_token_counts[ngram]\n",
    "    print(f\"N-gram '{ngram[0]} {ngram[1]} {ngram[2]} {ngram[3]}':\")\n",
    "    print(f\"Total count: {result['count']}\")\n",
    "    print(f\"Next tokens: {result['next_tokens']}\")\n",
    "\n",
    "    print(\"\\nRaw data:\")\n",
    "    print(from_ngram_to_next_token_counts[('to', 'be', 'or', 'not')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Distribution ðŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculating the **probability** of each n-gram's subsequent token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for ngram 'to be or not':\n",
      "{'to': 1.0}\n",
      "\n",
      "More examples:\n",
      "\n",
      "ngram 'the tragedie of julius':\n",
      "Probabilities: {'caesar': 1.0}\n",
      "\n",
      "ngram 'tragedie of julius caesar':\n",
      "Probabilities: {'by': 1.0}\n",
      "\n",
      "ngram 'of julius caesar by':\n",
      "Probabilities: {'william': 1.0}\n",
      "\n",
      "ngram 'julius caesar by william':\n",
      "Probabilities: {'shakespeare': 1.0}\n",
      "\n",
      "ngram 'caesar by william shakespeare':\n",
      "Probabilities: {'1599': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Calculating the probability of each ngram's subsequent token\n",
    "\n",
    "from_ngram_to_next_token_probs = {}\n",
    "\n",
    "def calculate_probabilities(counts_dict):\n",
    "\n",
    "    probs_dict = {}\n",
    "    \n",
    "    # For each ngram in the counts dictionary\n",
    "    for ngram, data in counts_dict.items():\n",
    "        total_count = data['count']\n",
    "        next_tokens = data['next_tokens']\n",
    "        \n",
    "        # Calculate probability for each next token\n",
    "        probs = {}\n",
    "        for token, count in next_tokens.items():\n",
    "            prob = count / total_count\n",
    "            probs[token] = round(prob, 3)  # Round to 3 decimal places\n",
    "            \n",
    "        probs_dict[ngram] = probs\n",
    "    \n",
    "    return probs_dict\n",
    "\n",
    "# Calculate probabilities\n",
    "from_ngram_to_next_token_probs = calculate_probabilities(from_ngram_to_next_token_counts)\n",
    "\n",
    "\n",
    "# Examples of probabilities depending on ngrams\n",
    "\n",
    "if n_grams == 2:\n",
    "\n",
    "    # Example probabilities for the same ngram we checked before\n",
    "    ngram = ('to', 'be')\n",
    "    print(f\"Probabilities for ngram '{ngram[0]} {ngram[1]}':\")\n",
    "    print(from_ngram_to_next_token_probs[ngram])\n",
    "\n",
    "    print(\"\\nMore examples:\")\n",
    "    for ngram, probs in list(from_ngram_to_next_token_probs.items())[:5]:\n",
    "        print(f\"\\nngram '{ngram[0]} {ngram[1]}':\")\n",
    "        print(f\"Probabilities: {probs}\")\n",
    "\n",
    "elif n_grams == 3:\n",
    "\n",
    "    # Example probabilities for the same ngram we checked before\n",
    "    ngram = ('to', 'be', 'or')\n",
    "    print(f\"Probabilities for ngram '{ngram[0]} {ngram[1]} {ngram[2]}':\")\n",
    "    print(from_ngram_to_next_token_probs[ngram])\n",
    "\n",
    "    print(\"\\nMore examples:\")\n",
    "    for ngram, probs in list(from_ngram_to_next_token_probs.items())[:5]:\n",
    "        print(f\"\\nngram '{ngram[0]} {ngram[1]} {ngram[2]}':\")\n",
    "        print(f\"Probabilities: {probs}\")\n",
    "\n",
    "elif n_grams == 4:\n",
    "\n",
    "    # Example probabilities for the same ngram we checked before\n",
    "    ngram = ('to', 'be', 'or', 'not')\n",
    "    print(f\"Probabilities for ngram '{ngram[0]} {ngram[1]} {ngram[2]} {ngram[3]}':\")\n",
    "    print(from_ngram_to_next_token_probs[ngram])\n",
    "\n",
    "    print(\"\\nMore examples:\")\n",
    "    for ngram, probs in list(from_ngram_to_next_token_probs.items())[:5]:\n",
    "        print(f\"\\nngram '{ngram[0]} {ngram[1]} {ngram[2]} {ngram[3]}':\")\n",
    "        print(f\"Probabilities: {probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Next Token ðŸŽ²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sampling the next token **based on the probability distribution** for a given ngram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sampling for ngram 'to be or not'\n",
      "Probability distribution: {'to': 1.0}\n",
      "\n",
      "Empirical distribution after 1000 samples:\n",
      "'to': 1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_next_token(ngram, prob_dict):\n",
    "    \"\"\"\n",
    "    Sample the next token based on the probability distribution for a given ngram.\n",
    "    \n",
    "    Args:\n",
    "        ngram (tuple): A tuple of tokens (previous tokens)\n",
    "        prob_dict (dict): Dictionary containing probability distributions for ngrams\n",
    "    \n",
    "    Returns:\n",
    "        str: The sampled next token\n",
    "        If ngram not found, returns None\n",
    "    \"\"\"\n",
    "    # Check if ngram exists in our probability dictionary\n",
    "    if ngram not in prob_dict:\n",
    "        return None\n",
    "    \n",
    "    # Get probability distribution for this ngram\n",
    "    next_token_probs = prob_dict[ngram]\n",
    "    \n",
    "    # Get tokens and their probabilities as separate lists\n",
    "    tokens = list(next_token_probs.keys())\n",
    "    probs = list(next_token_probs.values())\n",
    "    \n",
    "    # Normalize probabilities to ensure they sum to 1\n",
    "    probs_sum = sum(probs)\n",
    "    if probs_sum > 0:\n",
    "        probs = [p/probs_sum for p in probs]\n",
    "    \n",
    "    # Sample one token based on the probability distribution\n",
    "    next_token = np.random.choice(tokens, p=probs)\n",
    "    \n",
    "    return next_token\n",
    "\n",
    "\n",
    "# Test the sampling function depending on ngram\n",
    "if n_grams == 2:\n",
    "\n",
    "    test_ngram = ('to', 'be')\n",
    "    print(f\"Testing sampling for ngram '{test_ngram[0]} {test_ngram[1]}'\")\n",
    "    print(f\"Probability distribution: {from_ngram_to_next_token_probs[test_ngram]}\")\n",
    "\n",
    "    # Sample multiple times to see the distribution\n",
    "    n_samples = 1000\n",
    "    samples = [sample_next_token(test_ngram, from_ngram_to_next_token_probs) for _ in range(n_samples)]\n",
    "\n",
    "    # Calculate and print the empirical distribution\n",
    "    unique_tokens = set(samples)\n",
    "    empirical_dist = {token: samples.count(token)/n_samples for token in unique_tokens}\n",
    "\n",
    "    print(f\"\\nEmpirical distribution after {n_samples} samples:\")\n",
    "    for token, prob in empirical_dist.items():\n",
    "        print(f\"'{token}': {prob:.3f}\")\n",
    "\n",
    "if n_grams == 3:\n",
    "\n",
    "    test_ngram = ('to', 'be', 'or')\n",
    "    print(f\"Testing sampling for ngram '{test_ngram[0]} {test_ngram[1]} {test_ngram[2]}'\")\n",
    "    print(f\"Probability distribution: {from_ngram_to_next_token_probs[test_ngram]}\")\n",
    "\n",
    "    # Sample multiple times to see the distribution\n",
    "    n_samples = 1000\n",
    "    samples = [sample_next_token(test_ngram, from_ngram_to_next_token_probs) for _ in range(n_samples)]\n",
    "\n",
    "    # Calculate and print the empirical distribution\n",
    "    unique_tokens = set(samples)\n",
    "    empirical_dist = {token: samples.count(token)/n_samples for token in unique_tokens}\n",
    "\n",
    "    print(f\"\\nEmpirical distribution after {n_samples} samples:\")\n",
    "    for token, prob in empirical_dist.items():\n",
    "        print(f\"'{token}': {prob:.3f}\")\n",
    "\n",
    "if n_grams == 4:\n",
    "\n",
    "    test_ngram = ('to', 'be', 'or', 'not')\n",
    "    print(f\"Testing sampling for ngram '{test_ngram[0]} {test_ngram[1]} {test_ngram[2]} {test_ngram[3]}'\")\n",
    "    print(f\"Probability distribution: {from_ngram_to_next_token_probs[test_ngram]}\")\n",
    "\n",
    "    # Sample multiple times to see the distribution\n",
    "    n_samples = 1000\n",
    "    samples = [sample_next_token(test_ngram, from_ngram_to_next_token_probs) for _ in range(n_samples)]\n",
    "\n",
    "    # Calculate and print the empirical distribution\n",
    "    unique_tokens = set(samples)\n",
    "    empirical_dist = {token: samples.count(token)/n_samples for token in unique_tokens}\n",
    "\n",
    "    print(f\"\\nEmpirical distribution after {n_samples} samples:\")\n",
    "    for token, prob in empirical_dist.items():\n",
    "        print(f\"'{token}': {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text ðŸ“\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generating text starting from an n-gram and a specified amount of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text Examples:\n",
      "\n",
      "Starting with 'to be':\n",
      "to be or not to be that is the question whether tis nobler in the minde to suffer the slings\n",
      "\n",
      "Starting with 'truly you':\n",
      "truly you were not\n",
      "\n",
      "Starting with 'is this':\n",
      "is this a dagger which i see before me the handle toward my hand come let me clutch thee i\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text_from_ngram(initial_ngram, num_words, prob_dict):\n",
    "    \"\"\"\n",
    "    Generate text starting from an initial n-gram.\n",
    "    \n",
    "    Args:\n",
    "        initial_ngram (tuple): The starting n-gram\n",
    "        num_words (int): Number of words to generate\n",
    "        prob_dict (dict): Dictionary containing probability distributions\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated text\n",
    "    \"\"\"\n",
    "    # Initialize text with the initial n-gram\n",
    "    generated_words = list(initial_ngram)\n",
    "    \n",
    "    # Generate remaining words\n",
    "    current_ngram = initial_ngram\n",
    "    for _ in range(num_words - len(initial_ngram)):\n",
    "        # Sample next token\n",
    "        next_token = sample_next_token(current_ngram, prob_dict)\n",
    "        \n",
    "        # If we can't continue (no following tokens found), break\n",
    "        if next_token is None:\n",
    "            break\n",
    "            \n",
    "        # Add the new token to our generated text\n",
    "        generated_words.append(next_token)\n",
    "        \n",
    "        # Create new n-gram for next iteration\n",
    "        current_ngram = tuple(generated_words[-n_grams:])\n",
    "    \n",
    "    # Join all words with spaces\n",
    "    return ' '.join(generated_words)\n",
    "\n",
    "if n_grams == 2:\n",
    "\n",
    "    # Test the text generation with different initial n-grams\n",
    "    test_cases = [\n",
    "        ('to', 'be'),\n",
    "        ('truly', 'you'),\n",
    "        ('is', 'this')\n",
    "    ]\n",
    "\n",
    "    print(\"Generated Text Examples:\\n\")\n",
    "    for initial_ngram in test_cases:\n",
    "        print(f\"Starting with '{initial_ngram[0]} {initial_ngram[1]}':\")\n",
    "        generated_text = generate_text_from_ngram(initial_ngram, 20, from_ngram_to_next_token_probs)\n",
    "        print(f\"{generated_text}\\n\")\n",
    "\n",
    "if n_grams == 3:\n",
    "\n",
    "    # Test the text generation with different initial n-grams\n",
    "    test_cases = [\n",
    "        ('to', 'be', 'or'),\n",
    "        ('truly', 'you', 'were'),\n",
    "        ('is', 'this', 'a')\n",
    "    ]\n",
    "\n",
    "    print(\"Generated Text Examples:\\n\")\n",
    "    for initial_ngram in test_cases:\n",
    "        print(f\"Starting with '{initial_ngram[0]} {initial_ngram[1]}':\")\n",
    "        generated_text = generate_text_from_ngram(initial_ngram, 20, from_ngram_to_next_token_probs)\n",
    "        print(f\"{generated_text}\\n\")\n",
    "\n",
    "if n_grams == 4:\n",
    "\n",
    "    # Test the text generation with different initial n-grams\n",
    "    test_cases = [\n",
    "        ('to', 'be', 'or', 'not'),\n",
    "        ('truly', 'you', 'were', 'not'),\n",
    "        ('is', 'this', 'a', 'dagger')\n",
    "    ]\n",
    "\n",
    "    print(\"Generated Text Examples:\\n\")\n",
    "    for initial_ngram in test_cases:\n",
    "        print(f\"Starting with '{initial_ngram[0]} {initial_ngram[1]}':\")\n",
    "        generated_text = generate_text_from_ngram(initial_ngram, 20, from_ngram_to_next_token_probs)\n",
    "        print(f\"{generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results** ðŸ\n",
    "\n",
    "This examples are generted using 2, 3 and 4 ngrams with a longitude of 20 words.\n",
    "\n",
    "### **2-grams**\n",
    "\n",
    "**Starting with 'to be':**\n",
    "to be wrencht with an angry god macd i haue an immediate freedome of repeale caes what can the deuill\n",
    "\n",
    "**Starting with 'truly you':**\n",
    "truly you were sent for or no for he was not ambitious 1 if it be no assistant for a\n",
    "\n",
    "**Starting with 'is this':**\n",
    "is this that i must fall downe or else this braine of mine but vertue as it behoues my daughter\n",
    "\n",
    "### **3-grams**\n",
    "\n",
    "**Starting with 'to be':**\n",
    "to be or not to crack the winde of the poore phrase roaming it thus you l tender me a\n",
    "\n",
    "**Starting with 'truly you':**\n",
    "truly you were best cin what is my lord ham how say you then would heart of man once think\n",
    "\n",
    "**Starting with 'is this':**\n",
    "is this a dagger which i see before me the handle toward my hand come let me wipe thy face\n",
    "\n",
    "\n",
    "### **4-grams**\n",
    "\n",
    "**Starting with 'to be':**\n",
    "to be or not to be that is the question whether tis nobler in the minde to suffer the slings\n",
    "\n",
    "**Starting with 'truly you':**\n",
    "truly you were not\n",
    "\n",
    "**Starting with 'is this':**\n",
    "is this a dagger which i see before me the handle toward my hand come let me clutch thee i\n",
    "\n",
    "# **Analysis** ðŸ”\n",
    "\n",
    "The results from text generation using 2, 3, and 4-grams show a clear pattern in terms of coherence and fluency. Below is a brief analysis of each:\n",
    "\n",
    "### **2-grams**\n",
    "\n",
    "- The generated text lacks strong coherence, often forming disjointed phrases.\n",
    "\n",
    "- There are abrupt shifts in meaning, making it difficult to follow a logical sequence.\n",
    "\n",
    "- Some phrases resemble Shakespearean language but appear fragmented.\n",
    "\n",
    "### **3-grams**\n",
    "\n",
    "- Shows slight improvement in sentence structure compared to 2-grams.\n",
    "\n",
    "- Some phrases start to resemble coherent speech but still contain inconsistencies.\n",
    "\n",
    "- There are recognizable Shakespearean phrases, though they are often incomplete.\n",
    "\n",
    "### **4-grams**\n",
    "\n",
    "- Produces the most coherent and meaningful text.\n",
    "\n",
    "- Famous phrases, such as \"to be or not to be\" and \"is this a dagger which I see before me\", emerge naturally.\n",
    "\n",
    "- The output maintains better fluency and preserves original phrasing from Shakespearean texts.\n",
    "\n",
    "\n",
    "> As expected, **increasing the n-gram size improves** text coherence and fluency. While 2-grams produce fragmented and disjointed text, 4-grams generate recognizable and structured Shakespearean phrases. This suggests that **higher n-grams help retain more meaningful context, though they may still lack true creativity** or deeper understanding of language.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tests** ðŸ§ª\n",
    "\n",
    "Testing that all functions work as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_calculate_probabilities (__main__.TestShakespeareGenerator.test_calculate_probabilities)\n",
      "Test probability calculation ... ok\n",
      "test_count_next_token (__main__.TestShakespeareGenerator.test_count_next_token)\n",
      "Test token counting ... ok\n",
      "test_generate_text (__main__.TestShakespeareGenerator.test_generate_text)\n",
      "Test text generation ... ok\n",
      "test_get_ngrams (__main__.TestShakespeareGenerator.test_get_ngrams)\n",
      "Test n-gram generation ... ok\n",
      "test_preprocess_text (__main__.TestShakespeareGenerator.test_preprocess_text)\n",
      "Test text preprocessing ... ok\n",
      "test_sample_next_token (__main__.TestShakespeareGenerator.test_sample_next_token)\n",
      "Test token sampling ... ok\n",
      "test_shakespeare_specific (__main__.TestShakespeareGenerator.test_shakespeare_specific)\n",
      "Test with actual Shakespeare data ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.030s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from collections import defaultdict\n",
    "\n",
    "class TestShakespeareGenerator(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up test data\"\"\"\n",
    "        self.test_tokens = ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
    "        self.test_ngrams = list(nltk.ngrams(self.test_tokens, n_grams))\n",
    "        self.test_counts = {}\n",
    "        self.test_probs = {}\n",
    "        \n",
    "    def test_preprocess_text(self):\n",
    "        \"\"\"Test text preprocessing\"\"\"\n",
    "        test_text = ['Hello,', 'World!', 'Test.']\n",
    "        processed = preprocess_text(test_text)\n",
    "        self.assertEqual(processed, ['hello', 'world', 'test'])\n",
    "        \n",
    "    def test_get_ngrams(self):\n",
    "        \"\"\"Test n-gram generation\"\"\"\n",
    "        ngrams = get_ngrams(self.test_tokens, n_grams)\n",
    "        self.assertTrue(isinstance(ngrams, list))\n",
    "        self.assertTrue(all(len(gram) == n_grams for gram in ngrams))\n",
    "        \n",
    "    def test_count_next_token(self):\n",
    "        \"\"\"Test token counting\"\"\"\n",
    "        count_next_token(self.test_ngrams, self.test_tokens, self.test_counts, n_grams)\n",
    "        \n",
    "        # Check structure of counts dictionary\n",
    "        for ngram in self.test_counts:\n",
    "            self.assertIn('count', self.test_counts[ngram])\n",
    "            self.assertIn('next_tokens', self.test_counts[ngram])\n",
    "            self.assertTrue(isinstance(self.test_counts[ngram]['count'], int))\n",
    "            self.assertTrue(isinstance(self.test_counts[ngram]['next_tokens'], dict))\n",
    "            \n",
    "    def test_calculate_probabilities(self):\n",
    "        \"\"\"Test probability calculation\"\"\"\n",
    "        # First generate counts\n",
    "        count_next_token(self.test_ngrams, self.test_tokens, self.test_counts, n_grams)\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        self.test_probs = calculate_probabilities(self.test_counts)\n",
    "        \n",
    "        # Check probabilities sum to 1 (or close to 1 due to rounding)\n",
    "        for ngram in self.test_probs:\n",
    "            prob_sum = sum(self.test_probs[ngram].values())\n",
    "            self.assertAlmostEqual(prob_sum, 1.0, places=2)\n",
    "            \n",
    "    def test_sample_next_token(self):\n",
    "        \"\"\"Test token sampling\"\"\"\n",
    "        # First generate probabilities\n",
    "        count_next_token(self.test_ngrams, self.test_tokens, self.test_counts, n_grams)\n",
    "        self.test_probs = calculate_probabilities(self.test_counts)\n",
    "        \n",
    "        # Test sampling\n",
    "        if len(self.test_ngrams) > 0:\n",
    "            test_ngram = self.test_ngrams[0]\n",
    "            sampled_token = sample_next_token(test_ngram, self.test_probs)\n",
    "            \n",
    "            # Check if sampled token is in the possible next tokens\n",
    "            if sampled_token is not None:\n",
    "                self.assertIn(sampled_token, self.test_probs[test_ngram])\n",
    "                \n",
    "    def test_generate_text(self):\n",
    "        \"\"\"Test text generation\"\"\"\n",
    "        if len(self.test_ngrams) > 0:\n",
    "            initial_ngram = self.test_ngrams[0]\n",
    "            generated_text = generate_text_from_ngram(initial_ngram, 10, self.test_probs)\n",
    "            \n",
    "            # Check if generated text is a string and contains words\n",
    "            self.assertTrue(isinstance(generated_text, str))\n",
    "            self.assertTrue(len(generated_text.split()) > 0)\n",
    "            \n",
    "    def test_shakespeare_specific(self):\n",
    "        \"\"\"Test with actual Shakespeare data\"\"\"\n",
    "        # Test specific Shakespeare n-grams\n",
    "        if n_grams == 2:\n",
    "            test_ngram = ('to', 'be')\n",
    "        elif n_grams == 3:\n",
    "            test_ngram = ('to', 'be', 'or')\n",
    "        elif n_grams == 4:\n",
    "            test_ngram = ('to', 'be', 'or', 'not')\n",
    "            \n",
    "        # Check if the famous phrases are in our data\n",
    "        self.assertIn(test_ngram, from_ngram_to_next_token_probs)\n",
    "        \n",
    "        # Generate text from famous phrase\n",
    "        generated = generate_text_from_ngram(test_ngram, 10, from_ngram_to_next_token_probs)\n",
    "        self.assertTrue(isinstance(generated, str))\n",
    "        self.assertTrue(len(generated.split()) > 0)\n",
    "\n",
    "# Run the tests\n",
    "if __name__ == '__main__':\n",
    "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestShakespeareGenerator)\n",
    "    unittest.TextTestRunner(verbosity=2).run(test_suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
